{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<h1 style=\"text-align:center;\">Medical Research using Llama3 RAG</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "---\n",
    "\n",
    "In this project, we will use Llama 3 to implement a RAG project for question and answer functionality based on the source database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import ollama\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Download Medical Datasets\n",
    "\n",
    "---\n",
    "\n",
    "Sources:\n",
    "- https://www.moscmm.org/uploads/userfiles/Current%20Essentials%20of%20Medicine(1)(1).pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF files\n",
    "loader = PyPDFLoader(\"datasets/cecil-textbook-of-medicine.pdf\")\n",
    "\n",
    "# Load the pages\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DELETE: Sample\n",
    "pages = pages[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  5\n"
     ]
    }
   ],
   "source": [
    "# PDF info\n",
    "print(\"Number of pages: \", len(pages))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and hypomagnesemia. \n",
      "53\n",
      " Figure 16-3  Screening and brief intervention for alcohol problems in clinical practice.\n",
      "Alcoholic hypoglycemia (see Chapter 243)  can be evaluated rapidly by a bedside blood glucose determination. If laboratory results are delayed, 12.5 to 25 g glucose \n",
      "should be given intravenously but must be preceded by or accompanied by 100 mg intravenous thiamine to avoid precipitating Wern icke's encephalopathy (see \n",
      "Chapter 489)  . Alcoholic ketoacidosis (see Chapter 102)  will b\n",
      "{'source': 'datasets/cecil-textbook-of-medicine.pdf', 'page': 100}\n"
     ]
    }
   ],
   "source": [
    "# Retrive a page\n",
    "page = pages[0]                      # First page\n",
    "\n",
    "# Page info\n",
    "print(page.page_content[0:500])      # Print first 500 characters\n",
    "print(page.metadata)                 # Page metadata  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soheil\\.conda\\envs\\llama3-RAG\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text splitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "# text_splitter = SemanticChunker(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Vector Database\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ollama embeddings \n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['621fbf5a-5117-4fad-8a73-f540d9d1a16b',\n",
       " '4f364154-634b-4710-9456-058df17c5da6',\n",
       " '5c4c6c6a-6cb9-4d48-9387-669a78319752',\n",
       " 'e7dce7f3-604a-4d34-a68a-0144d32adc28',\n",
       " 'f7e44ca7-a4fd-4d7c-80a2-7f7ab67b12eb',\n",
       " '2314b326-d662-4559-9f49-4f12dc8156e3',\n",
       " '767211fc-4eba-4a86-8e9d-f2c186745a5e',\n",
       " '44a5f5b8-f6fa-4148-b625-7ac6356c1e40',\n",
       " '2459e1e7-ffe7-47f9-9fb3-753879c3f34e',\n",
       " '57eca68b-048c-4550-af99-020f7a3c7ea7',\n",
       " 'b192344f-19e5-4ca6-bff5-989213438aec',\n",
       " '7a606bff-3e7c-4320-9fe9-fa5e4841f98f',\n",
       " 'a53a7803-8825-4d2e-b7a6-ac3dd0837690',\n",
       " '5d9c30fd-8cb3-4b36-bb19-f28dd5f40307',\n",
       " 'cd9ff211-9dae-4fe2-93d1-d37deb5718dc',\n",
       " 'f5f04ced-c318-4785-9133-8c0fdc5fc7ba',\n",
       " 'e9baa24f-77e7-4d36-bbaa-cc1018488afd',\n",
       " 'ce66009f-30fa-4f98-a2f9-46bc3588dd4e',\n",
       " '76d239ed-3fcc-4897-a445-72bbccd28798',\n",
       " '33b89450-1ea6-4a8c-89d5-f011b3e8a058',\n",
       " '2beb4e4e-fc5a-4340-8f4a-82fdfac16b9b',\n",
       " '1ce2f587-f75f-46d7-89e1-700a9ebab268',\n",
       " 'b50f91e9-d301-43af-ac53-eff69d0a653d']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index documents using Chroma and OllamaEmbeddings\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "vector_store.add_documents(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x16290c8c8b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Ollama Llama-3 Model\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to handle the entire RAG chain process\n",
    "def answer_question_with_context(question):\n",
    "\n",
    "    # Retrieve documents relevant to the question\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # Combine the content of the retrieved documents into a single string\n",
    "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    \n",
    "    # Format the prompt for the LLM\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {formatted_context}\"\n",
    "    \n",
    "    # Get the response from the LLM\n",
    "    response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    \n",
    "    # Return the content of the response\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Withdrawal symptoms of heroin:\\n\\n* Vital signs:\\n\\t+ Tachycardia\\n\\t+ Hypertension\\n\\t+ Fever\\n* Central nervous system:\\n\\t+ Craving\\n\\t+ Restlessness\\n\\t+ Insomnia\\n\\t+ Muscle cramps\\n\\t+ Yawning\\n\\t+ Miosis (pinpoint pupils)\\n* Eyes, nose, and lacrimation:\\n\\t+ Lacrimation (tearing)\\n\\t+ Rhinorrhea (runny nose)\\n* Skin:\\n\\t+ Perspiration'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample prompt\n",
    "prompt = \"What's withdrawal symptoms of heroin?\"\n",
    "\n",
    "# Get an answer \n",
    "result = answer_question_with_context(prompt)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Withdrawal symptoms of heroin:',\n",
      " '',\n",
      " '* Vital signs:',\n",
      " '\\t+ Tachycardia',\n",
      " '\\t+ Hypertension',\n",
      " '\\t+ Fever',\n",
      " '* Central nervous system:',\n",
      " '\\t+ Craving',\n",
      " '\\t+ Restlessness',\n",
      " '\\t+ Insomnia',\n",
      " '\\t+ Muscle cramps',\n",
      " '\\t+ Yawning',\n",
      " '\\t+ Miosis (pinpoint pupils)',\n",
      " '* Eyes, nose, and lacrimation:',\n",
      " '\\t+ Lacrimation (tearing)',\n",
      " '\\t+ Rhinorrhea (runny nose)',\n",
      " '* Skin:',\n",
      " '\\t+ Perspiration']\n"
     ]
    }
   ],
   "source": [
    "pprint(result.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
